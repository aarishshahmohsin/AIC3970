import numpy as np


import matplotlib.pyplot as plt


class Perceptron:
    def __init__(self, input_size, lr=0.1, epochs=100):
        self.weights = np.zeros(input_size + 1) 
        self.lr = lr 
        self.epochs = epochs  

    def activation(self, x):
        return 1 if x >= 0 else 0

    def predict(self, inputs):
        summation = np.dot(inputs, self.weights[1:]) + self.weights[0] 
        return self.activation(summation)

    def train(self, training_data, labels):
        for _ in range(self.epochs):
            for inputs, label in zip(training_data, labels):
                prediction = self.predict(inputs)
                self.weights[1:] += self.lr * (label - prediction) * inputs 
                self.weights[0] += self.lr * (label - prediction)  

def generate_linearly_separable_data():
    np.random.seed(42)
    class_0 = np.random.randn(100, 2) + np.array([2, 2])
    class_1 = np.random.randn(100, 2) + np.array([-2, -2])
    data = np.vstack((class_0, class_1))
    labels = np.hstack((np.zeros(100), np.ones(100)))
    return data, labels

def plot_decision_boundary(perceptron, data, labels):
    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='bwr', edgecolors='k')
    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1
    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1

    w1, w2 = perceptron.weights[1], perceptron.weights[2]
    c = perceptron.weights[0]

    x1 = np.linspace(x_min, x_max, 100)
    x2 = -(w1 * x1 + c) / w2 
    plt.plot(x1, x2, color='black', linewidth=2, label="Decision Boundary")

    plt.title("Perceptron Decision Boundary")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.legend()
    plt.show()


data, labels = generate_linearly_separable_data()

perceptron = Perceptron(input_size=2, lr=0.1, epochs=100)

perceptron.train(data, labels)


plot_decision_boundary(perceptron, data, labels)


perceptron = Perceptron(input_size=2, lr=0.1, epochs=100)

x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) 
y = np.array([0, 1, 1, 1])
perceptron.train(x, y)

plot_decision_boundary(perceptron, x, y)


def xor_network():
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 1, 1, 0])
    # XOR(x1,x2)=OR(x1,x2)âˆ§NAND(x1,x2)
    
    perceptron_h1 = Perceptron(input_size=2, lr=0.1, epochs=1000)
    perceptron_h2 = Perceptron(input_size=2, lr=0.1, epochs=1000)
    perceptron_h3 = Perceptron(input_size=2, lr=0.1, epochs=1000)
    perceptron_h4 = Perceptron(input_size=2, lr=0.1, epochs=1000)
 
    perceptron_o = Perceptron(input_size=4, lr=0.1, epochs=1000)
    
    perceptron_h1.train(X, np.array([0, 1, 1, 1]))  
    perceptron_h2.train(X, np.array([0, 0, 0, 1]))  
    perceptron_h3.train(X, np.array([1, 0, 0, 0]))  
    perceptron_h4.train(X, np.array([1, 1, 1, 0]))  

    h1_output = np.array([perceptron_h1.predict(x) for x in X])
    h2_output = np.array([perceptron_h2.predict(x) for x in X])
    h3_output = np.array([perceptron_h3.predict(x) for x in X])
    h4_output = np.array([perceptron_h4.predict(x) for x in X])
    hidden_outputs = np.column_stack((h1_output, h2_output, h3_output, h4_output))

    perceptron_o.train(hidden_outputs, y)

    predictions = []
    for x in X:
        h1 = perceptron_h1.predict(x)
        h2 = perceptron_h2.predict(x)
        h3 = perceptron_h3.predict(x)
        h4 = perceptron_h4.predict(x)
        predictions.append(perceptron_o.predict(np.array([h1, h2, h3, h4])))

    return X, y, predictions, perceptron_h1, perceptron_h2, perceptron_h3, perceptron_h4, perceptron_o

def plot_decision_boundary(X, y, perceptron_h1, perceptron_h2, perceptron_h3, perceptron_h4, perceptron_o):
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))

    Z = np.zeros(xx.shape)
    for i in range(xx.shape[0]):
        for j in range(xx.shape[1]):
            x1 = xx[i, j]
            x2 = yy[i, j]
            h1 = perceptron_h1.predict(np.array([x1, x2]))
            h2 = perceptron_h2.predict(np.array([x1, x2]))
            h3 = perceptron_h3.predict(np.array([x1, x2]))
            h4 = perceptron_h4.predict(np.array([x1, x2]))
            Z[i, j] = perceptron_o.predict(np.array([h1, h2, h3, h4]))

    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k', s=100)
    plt.title("Non-linear Decision Boundary for XOR")
    plt.xlabel("Input 1")
    plt.ylabel("Input 2")
    plt.show()

X, y, predictions, perceptron_h1, perceptron_h2, perceptron_h3, perceptron_h4, perceptron_o = xor_network()

print("Inputs:", X)
print("True XOR Outputs:", y)
print("Predicted XOR Outputs:", predictions)

plot_decision_boundary(X, y, perceptron_h1, perceptron_h2, perceptron_h3, perceptron_h4, perceptron_o)


def generate_xor_data_3d():
    # Generate all possible combinations of 0 and 1 for 3 dimensions
    X = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1],
                  [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])
    # XOR output is 1 if the number of 1's is odd, else 0
    y = np.sum(X, axis=1) % 2
    return X, y

def xor_network_3d():
    # Generate XOR data for 3 dimensions
    X, y = generate_xor_data_3d()

    # Initialize perceptrons
    hidden_layer_size = 8  # 2^3 = 8 neurons
    hidden_perceptrons = [Perceptron(input_size=3, lr=0.1, epochs=1000) for _ in range(hidden_layer_size)]
    perceptron_o = Perceptron(input_size=hidden_layer_size, lr=0.1, epochs=1000)

    # Train hidden layer perceptrons with random intermediate labels
    for perceptron in hidden_perceptrons:
        intermediate_labels = np.random.randint(0, 2, size=len(y))  # Random labels
        perceptron.train(X, intermediate_labels)

    # Get hidden layer outputs
    hidden_outputs = np.array([[perceptron.predict(x) for perceptron in hidden_perceptrons] for x in X])

    # Train output layer perceptron
    perceptron_o.train(hidden_outputs, y)

    # Predict using the network
    predictions = []
    for x in X:
        hidden_output = np.array([perceptron.predict(x) for perceptron in hidden_perceptrons])
        predictions.append(perceptron_o.predict(hidden_output))

    return X, y, predictions, hidden_perceptrons, perceptron_o

def plot_decision_boundary_2d_slice(X, y, hidden_perceptrons, perceptron_o, fixed_values=None):
    if fixed_values is None:
        fixed_values = [0] * (X.shape[1] - 2)  # Default to 0 for fixed dimensions

    # Create a grid of points over the first two dimensions
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))

    # Evaluate the network's predictions over the grid
    Z = np.zeros(xx.shape)
    for i in range(xx.shape[0]):
        for j in range(xx.shape[1]):
            x1 = xx[i, j]
            x2 = yy[i, j]
            input_point = np.array([x1, x2] + fixed_values)
            hidden_output = np.array([perceptron.predict(input_point) for perceptron in hidden_perceptrons])
            Z[i, j] = perceptron_o.predict(hidden_output)

    # Plot the decision boundary
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k', s=100)
    plt.title(f"2D Slice of Decision Boundary (Fixed Dimensions: {fixed_values})")
    plt.xlabel("Input 1")
    plt.ylabel("Input 2")
    plt.show()

# Run the XOR network for 3 dimensions
X, y, predictions, hidden_perceptrons, perceptron_o = xor_network_3d()

# Print predictions
print("Inputs:", X)
print("True XOR Outputs:", y)
print("Predicted XOR Outputs:", predictions)

# Plot a 2D slice of the decision boundary
plot_decision_boundary_2d_slice(X, y, hidden_perceptrons, perceptron_o, fixed_values=[0])


def generate_xor_data(n_dimensions):
    X = np.array(np.meshgrid(*[[0, 1]] * n_dimensions)).T.reshape(-1, n_dimensions)
    y = np.sum(X, axis=1) % 2
    return X, y

def xor_network(n_dimensions):
    # Generate XOR data
    X, y = generate_xor_data(n_dimensions)

    # Initialize perceptrons
    hidden_layer_size = 2**n_dimensions  # 2^n neurons
    hidden_perceptrons = [Perceptron(input_size=n_dimensions, lr=0.1, epochs=1000) for _ in range(hidden_layer_size)]
    perceptron_o = Perceptron(input_size=hidden_layer_size, lr=0.1, epochs=1000)

    # Train hidden layer perceptrons with random intermediate labels
    for perceptron in hidden_perceptrons:
        intermediate_labels = np.random.randint(0, 2, size=len(y))  # Random labels
        perceptron.train(X, intermediate_labels)

    # Get hidden layer outputs
    hidden_outputs = np.array([[perceptron.predict(x) for perceptron in hidden_perceptrons] for x in X])

    # Train output layer perceptron
    perceptron_o.train(hidden_outputs, y)

    # Predict using the network
    predictions = []
    for x in X:
        hidden_output = np.array([perceptron.predict(x) for perceptron in hidden_perceptrons])
        predictions.append(perceptron_o.predict(hidden_output))

    return X, y, predictions, hidden_perceptrons, perceptron_o

def plot_decision_boundary_2d_slice(X, y, hidden_perceptrons, perceptron_o, fixed_values=None):
    if fixed_values is None:
        fixed_values = [0] * (X.shape[1] - 2)  # Default to 0 for fixed dimensions

    # Create a grid of points over the first two dimensions
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))

    # Evaluate the network's predictions over the grid
    Z = np.zeros(xx.shape)
    for i in range(xx.shape[0]):
        for j in range(xx.shape[1]):
            x1 = xx[i, j]
            x2 = yy[i, j]
            input_point = np.array([x1, x2] + fixed_values)
            hidden_output = np.array([perceptron.predict(input_point) for perceptron in hidden_perceptrons])
            Z[i, j] = perceptron_o.predict(hidden_output)

    # Plot the decision boundary
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='bwr')
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolors='k', s=100)
    plt.title(f"2D Slice of Decision Boundary (Fixed Dimensions: {fixed_values})")
    plt.xlabel("Input 1")
    plt.ylabel("Input 2")
    plt.show()

# Example usage for n dimensions
n_dimensions = 3  # Change this to any number of dimensions
X, y, predictions, hidden_perceptrons, perceptron_o = xor_network(n_dimensions)

# Print predictions
print("Inputs:", X)
print("True XOR Outputs:", y)
print("Predicted XOR Outputs:", predictions)

# Plot a 2D slice of the decision boundary
plot_decision_boundary_2d_slice(X, y, hidden_perceptrons, perceptron_o, fixed_values=[0])



