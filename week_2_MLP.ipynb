{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ae5599-a20a-4138-9f5e-0fd326f33a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f819eec-7057-482b-b516-f270eb582cee",
   "metadata": {},
   "source": [
    "\n",
    "CRIM - per capita crime rate by town \n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per 10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907b5d3a-cb49-4ec9-9187-9086d06f7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    boston = fetch_openml(name='boston', version=1, as_frame=False)\n",
    "    X, y = boston.data, boston.target.reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0031ef-1e34-4197-8c48-35609452a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(input_size, hidden1_size, hidden2_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    weights = {\n",
    "        \"W1\": np.random.randn(input_size, hidden1_size),\n",
    "        \"b1\": np.zeros((1, hidden1_size)),\n",
    "        \"W2\": np.random.randn(hidden1_size, hidden2_size),\n",
    "        \"b2\": np.zeros((1, hidden2_size)),\n",
    "        \"W3\": np.random.randn(hidden2_size, output_size),\n",
    "        \"b3\": np.zeros((1, output_size))\n",
    "    }\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf0bc80-4cfb-46dd-b05b-56b21d9e5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e10cf40-b3e2-4ac4-9b60-af1ab9c3048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, weights):\n",
    "    Z1 = np.dot(X, weights[\"W1\"]) + weights[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    Z2 = np.dot(A1, weights[\"W2\"]) + weights[\"b2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    Z3 = np.dot(A2, weights[\"W3\"]) + weights[\"b3\"]\n",
    "    return Z1, A1, Z2, A2, Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cab8ac-e505-4630-83df-c9fc4604355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, y, weights, Z1, A1, Z2, A2, Z3, learning_rate, batch_size):\n",
    "    error = y - Z3  # Compute error\n",
    "    dZ3 = -2 * error / batch_size  # Compute derivative of loss w.r.t output\n",
    "    \n",
    "    # Compute gradients for output layer:\n",
    "    # dL/dW3 = A2^T * dZ3\n",
    "    dW3 = np.dot(A2.T, dZ3)\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute gradients for hidden layer 2:\n",
    "    # dL/dA2 = dZ3 * W3^T\n",
    "    # dL/dZ2 = dL/dA2 * sigmoid_derivative(A2)\n",
    "    dA2 = np.dot(dZ3, weights[\"W3\"].T) * sigmoid_derivative(A2)\n",
    "    dW2 = np.dot(A1.T, dA2)\n",
    "    db2 = np.sum(dA2, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute gradients for hidden layer 1:\n",
    "    # dL/dA1 = dA2 * W2^T\n",
    "    # dL/dZ1 = dL/dA1 * sigmoid_derivative(A1)\n",
    "    dA1 = np.dot(dA2, weights[\"W2\"].T) * sigmoid_derivative(A1)\n",
    "    dW1 = np.dot(X.T, dA1)\n",
    "    db1 = np.sum(dA1, axis=0, keepdims=True)\n",
    "    \n",
    "    # Update weights using gradient descent\n",
    "    weights[\"W3\"] -= learning_rate * dW3\n",
    "    weights[\"b3\"] -= learning_rate * db3\n",
    "    weights[\"W2\"] -= learning_rate * dW2\n",
    "    weights[\"b2\"] -= learning_rate * db2\n",
    "    weights[\"W1\"] -= learning_rate * dW1\n",
    "    weights[\"b1\"] -= learning_rate * db1\n",
    "    \n",
    "    return weights, np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35a70306-aa73-449f-ac5e-f54417a99d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, weights, learning_rate=0.01, batch_size=32, epochs=600):\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        indices = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        X_train_shuffled = X_train[indices]\n",
    "        y_train_shuffled = y_train[indices]\n",
    "        \n",
    "        for start in range(0, X_train.shape[0], batch_size):\n",
    "            end = start + batch_size\n",
    "            X_batch, y_batch = X_train_shuffled[start:end], y_train_shuffled[start:end]\n",
    "            \n",
    "            Z1, A1, Z2, A2, Z3 = forward_pass(X_batch, weights)\n",
    "            weights, mse = backpropagation(X_batch, y_batch, weights, Z1, A1, Z2, A2, Z3, learning_rate, batch_size)\n",
    "        \n",
    "        # print(f\"Epoch {epoch + 1}, Mean Squared Error: {mse}\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a941a2f0-77bc-4dcb-be23-fd98c8dad377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    _, _, _, _, Z3 = forward_pass(X, weights)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a637eb-31ee-4936-9d64-8bed13f86303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|â–ˆ| 600/600 [00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 12.859007665455895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()\n",
    "weights = initialize_weights(input_size=X_train.shape[1], hidden1_size=8, hidden2_size=6, output_size=1)\n",
    "weights = train(X_train, y_train, weights)\n",
    "\n",
    "y_pred = predict(X_test, weights)\n",
    "test_mse = np.mean((y_test - y_pred) ** 2)\n",
    "print(f\"Test Mean Squared Error: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb4cc4-d823-4e24-a85a-f625655b5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(8, 6), activation='logistic', solver='sgd', learning_rate_init=0.01, max_iter=600, random_state=42)\n",
    "mlp.fit(X_train, y_train.ravel())\n",
    "y_pred_sklearn = mlp.predict(X_test)\n",
    "test_mse_sklearn = mean_squared_error(y_test, y_pred_sklearn)\n",
    "print(f\"Sklearn MLP Test Mean Squared Error: {test_mse_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15faac-8793-4b6b-a3c8-cd4093ea36a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7087ab9a-136e-4583-b40e-6dc59134a168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
